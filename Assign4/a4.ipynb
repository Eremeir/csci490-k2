{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Name & Z-ID\n",
    "Matt Borek\n",
    "\n",
    "z1951125\n",
    "\n",
    "bro ftext had to become a gross tuple mess and I had to figure out tuple unpacking and repacking \n",
    "all just to avoid rescanning the text for the book title and getting 5 extra credit\n",
    "\n",
    "not sure if worth the hassle tbh but it works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def download_text(url):\n",
    "    local_fname = os.path.basename(url)\n",
    "    if not os.path.exists(local_fname):\n",
    "        urlretrieve(url, local_fname)\n",
    "    return local_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = download_text('https://www.gutenberg.org/files/17610/17610-8.txt'), \"iso-8859-1\" #(encoding: iso-8859-1)\n",
    "fname2 = download_text('https://www.gutenberg.org/files/63438/63438-0.txt'), \"utf-8-sig\" #(encoding: utf-8-sig)\n",
    "fname3 = download_text('https://www.gutenberg.org/files/63439/63439-0.txt'), \"utf-8-sig\" #(encoding: utf-8-sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_data(fname):\n",
    "    filename, encoding = fname[0], fname[1]\n",
    "    with open(filename, 'r', encoding=encoding) as text:\n",
    "        section_found = False\n",
    "        title_found = False\n",
    "        text_lines = []\n",
    "        for line in text:\n",
    "            if not section_found and not title_found:\n",
    "                book_title = re.match(r'^Title:\\s*(.*?)\\s*$', line)\n",
    "                if book_title is not None:\n",
    "                    title_found = True\n",
    "                    book_title = book_title.group(1)\n",
    "                \n",
    "            if re.match(r'\\*{3} START OF THIS PROJECT GUTENBERG EBOOK .*? \\*{3}', line):\n",
    "                section_found = True\n",
    "                continue\n",
    "            \n",
    "            if re.match(r'\\*{3} END OF THIS PROJECT GUTENBERG EBOOK .*? \\*{3}', line):\n",
    "                section_found = False\n",
    "                break\n",
    "            \n",
    "            if section_found:\n",
    "                text_lines.append(line.strip())\n",
    "    return text_lines, book_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftext = read_data(fname)\n",
    "ftext2 = read_data(fname2)\n",
    "ftext3 = read_data(fname3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find Non-ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_ASCII(text_lines):\n",
    "    non_ASCII = set()\n",
    "    for line in text_lines:\n",
    "        for char in line:\n",
    "            if ord(char) > 128:\n",
    "                non_ASCII.add(char)\n",
    "    return non_ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "46\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(find_non_ASCII(*ftext[:1])))\n",
    "print(len(find_non_ASCII(*ftext2[:1])))\n",
    "print(len(find_non_ASCII(*ftext3[:1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convert Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quotes(text_lines):\n",
    "    conversions = {'‘':'\\'',\n",
    "                   '’':'\\'',\n",
    "                   '“':'\"',\n",
    "                   '”':'\"',\n",
    "                   '«':'\"',\n",
    "                   '»':'\"',\n",
    "                }\n",
    "    return [''.join([(char if char not in conversions else conversions[char]) for char in line]) for line in text_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftext = convert_quotes(*ftext[:1]), *ftext[1:2]\n",
    "ftext2 = convert_quotes(*ftext2[:1]), *ftext2[1:2]\n",
    "ftext3 = convert_quotes(*ftext3[:1]), *ftext3[1:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert Underscores (Italics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_underscores(text_lines):\n",
    "    regex = r'(?<=\\b)_(?=\\S)(.*?)(?<=\\S)_(?=\\b)'\n",
    "    for i, line in enumerate(text_lines):\n",
    "        text_lines[i] = re.sub(regex, r'<i>\\1</i>', line)\n",
    "    return text_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftext = convert_underscores(*ftext[:1]), *ftext[1:2]\n",
    "ftext2 = convert_underscores(*ftext2[:1]), *ftext2[1:2]\n",
    "ftext3 = convert_underscores(*ftext3[:1]), *ftext3[1:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Count Headers & Roman Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_headers_romans(text_lines):\n",
    "    headers = 0\n",
    "    romans = 0\n",
    "    roman_regex = r'^(?=[MDCLXVI])M*(C[MD]|D?C{0,3})(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$'\n",
    "    for line in text_lines:\n",
    "        if not line.isupper():\n",
    "            continue\n",
    "        elif re.match(roman_regex, line):\n",
    "            romans += 1\n",
    "        else:\n",
    "            headers += 1\n",
    "    return headers, romans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 2)\n",
      "(110, 105)\n",
      "(164, 27)\n"
     ]
    }
   ],
   "source": [
    "print(count_headers_romans(*ftext[:1]))\n",
    "print(count_headers_romans(*ftext2[:1]))\n",
    "print(count_headers_romans(*ftext3[:1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(ftext, fname):\n",
    "    text_lines, book_title = ftext[0], ftext[1]\n",
    "    filename, encoding = fname[0], fname[1]\n",
    "    headers, romans = count_headers_romans(*ftext[:1])\n",
    "    with open(filename[:-4]+\"-converted.txt\", 'w', encoding=\"utf-8-sig\") as outf:\n",
    "        text_lines.insert(0, \"From Project Gutenberg (www.gutenberg.org)\")\n",
    "        text_lines.insert(1, \"Converted by: Matt Borek\")\n",
    "        text_lines.insert(2, f\"\\n*** START OF THE EBOOK {book_title.upper()} ***\")\n",
    "        text_lines.append(f\"*** END OF THE EBOOK {book_title.upper()} ***\\n\")\n",
    "        text_lines.append(f\"Number of Headers:{headers:>19}\") #Instructions don't specify any field width so I just used the width necessary to match the reference output.\n",
    "        text_lines.append(f\"Number of Roman Numerals:{romans:>12}\")\n",
    "        for line in text_lines:\n",
    "            line = line+'\\n'\n",
    "            outf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(ftext, fname)\n",
    "write_output(ftext2, fname2)\n",
    "write_output(ftext3, fname3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i actually hate tuples now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
